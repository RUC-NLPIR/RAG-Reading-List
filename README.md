# RAG-Reading-List

This repository is used to collect recent studies on RAG methods, benchmarks, and toolkits. Welcome any updates through pull requests.

## 📄 Method

### Text only

1. **In-Context Retrieval-Augmented Language Models**
   - arXiv, 2023-08-01, https://arxiv.org/abs/2302.00083
   - Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham
   - Using retrieved results can effectively imrpove LLMs' performance. Retrieve after every $k$ tokens, and the performance can be improved when $k$ is small (more frequent retrieval). Reranking is also helpful.
2. **PlanXRAG: Planning-guided Retrieval Augmented Generation**
   - arXiv, 2024-10-28, https://arxiv.org/abs/2410.20753
   - Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

### Multimodal

## 📊 Benchmark

## 🛠️ Toolkit

