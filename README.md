# RAG-Reading-List

This repository is used to collect recent studies on RAG methods, benchmarks, and toolkits. Welcome any updates through pull requests.

## 📄 Method

### Text only

1. **In-Context Retrieval-Augmented Language Models**
   - arXiv, 2023-08-01, https://arxiv.org/abs/2302.00083
   - Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham
   - Using retrieved results can effectively imrpove LLMs' performance. Retrieve after every $k$ tokens, and the performance can be improved when $k$ is small (more frequent retrieval). Reranking is also helpful.
2. **PlanXRAG: Planning-guided Retrieval Augmented Generation**
   - arXiv, 2024-10-28, https://arxiv.org/abs/2410.20753
   - Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma
3. **RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation**
   - arXiv, 2024-03-31 , https://arxiv.org/abs/2404.00610
   - Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo, Wei Xue, Yike Guo, Jie Fu

### Multimodal

## 📊 Benchmark

## 🛠️ Toolkit

